import streamlit as st

# openai ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (app.py ìƒë‹¨ì—ì„œ import ê¶Œì¥)
from openai import OpenAI


st.title("ğŸ§  ì‹¬ë¦¬ìƒë‹´ ì±—ë´‡ (Solar Pro2)")

# Upstage Solar Pro2 API í‚¤ì™€ ì—”ë“œí¬ì¸íŠ¸
client = OpenAI(
    api_key= st.secrets["OPENAI_API_KEY"],
    base_url="https://api.upstage.ai/v1"
)

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”. ì‹¬ë¦¬ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”."}
    ]

# ì´ì „ ëŒ€í™” ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ê³ ë¯¼ì´ë‚˜ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Upstage Solar Pro2ë¡œ ë©”ì‹œì§€ ì „ì†¡ (ìŠ¤íŠ¸ë¦¬ë°)
    with st.chat_message("assistant"):
        stream = client.chat.completions.create(
            model="solar-pro2",
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            stream=True,
        )
        response_text = ""
        response_area = st.empty()
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                response_text += chunk.choices[0].delta.content
                response_area.markdown(response_text + "â–Œ")
        response_area.markdown(response_text)
    st.session_state.messages.asppend({"role": "assistant", "content": response_text})

